{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install wordninja\n","!pip install fuzzywuzzy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BcrXOr4bPCGq","outputId":"59e3e604-0029-48c9-9b2a-05d1dc6c6861","executionInfo":{"status":"ok","timestamp":1742044591172,"user_tz":-330,"elapsed":18426,"user":{"displayName":"Naveen Dhawan","userId":"01177328456143024234"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wordninja\n","  Downloading wordninja-2.0.0.tar.gz (541 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/541.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/541.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m532.5/541.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.6/541.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: wordninja\n","  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541530 sha256=55b37317dd9c02957a029283e03bbeaf9a7976ae23bf6ae95bbca207ab3e8625\n","  Stored in directory: /root/.cache/pip/wheels/e6/66/9c/712044a983337f5d44f90abcd244bd4b8ad28ee64750404b50\n","Successfully built wordninja\n","Installing collected packages: wordninja\n","Successfully installed wordninja-2.0.0\n","Collecting fuzzywuzzy\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n","Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Installing collected packages: fuzzywuzzy\n","Successfully installed fuzzywuzzy-0.18.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgMgvfQ7Of2r","outputId":"54ec5b65-67bd-4e1a-f0f4-335d6d81e172"},"outputs":[{"output_type":"stream","name":"stdout","text":["Formatted data saved to Cleanedexltask1.xlsx\n"]}],"source":["import pandas as pd\n","import re\n","import wordninja  # Install via pip install wordninja\n","\n","# Add a custom dictionary to handle specific cases like 'Baler'\n","custom_words = ['baler']  # Add any other problematic words here\n","\n","# Function to format text\n","def format_text(text):\n","    if isinstance(text, str):  # Ensure the value is a string\n","        # Step 1: Convert to lowercase\n","        text = text.lower()\n","\n","        # Step 2: Replace dots and underscores with spaces\n","        text = text.replace('.', ' ').replace('_', ' ')\n","\n","        # Step 3: Add spaces after punctuation marks like :, ;, -, /, etc.\n","        text = re.sub(r'([:,;\\/-])([a-zA-Z0-9])', r'\\1 \\2', text)\n","\n","        # Step 4: Split concatenated words using wordninja\n","        words = []\n","        for token in text.split():\n","            # Use wordninja to split concatenated words, checking for custom words first\n","            if token in custom_words:\n","                words.append(token)  # If it's a custom word, add it as is\n","            else:\n","                split_words = wordninja.split(token)\n","                words.extend(split_words)\n","\n","        # Join the split words back into a single string\n","        text = ' '.join(words)\n","\n","        # Step 5: Capitalize the first letter of each sentence\n","        text = '. '.join(sentence.strip().capitalize() for sentence in text.split('.'))\n","\n","        # Step 6: Remove any remaining extra spaces\n","        text = ' '.join(text.split())\n","\n","    return text\n","\n","# Read the Excel file\n","file_path = '/content/DA - Task 1..xlsx'\n","\n","# Read both sheets\n","df_task = pd.read_excel(file_path, sheet_name='Task')\n","df_taxonomy = pd.read_excel(file_path, sheet_name='Taxonomy')\n","\n","# Apply formatting to the specified columns in the 'Task' sheet\n","columns_to_format = ['Product Category', 'Complaint', 'Cause', 'Correction']\n","for column in columns_to_format:\n","    df_task[column] = df_task[column].apply(format_text)\n","\n","# Save both sheets ('Task' and 'Taxonomy') to a new Excel file\n","output_file_path = 'Cleanedexltask1.xlsx'\n","with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n","    df_task.to_excel(writer, sheet_name='Task', index=False)\n","    df_taxonomy.to_excel(writer, sheet_name='Taxonomy', index=False)\n","\n","print(f\"Formatted data saved to {output_file_path}\")"]},{"cell_type":"code","source":["import pandas as pd\n","from fuzzywuzzy import process\n","\n","# Load the Excel file\n","file_path = \"/content/Cleanedexltask1.xlsx\"  # Update with your file path\n","task_sheet = pd.read_excel(file_path, sheet_name=\"Task\")\n","taxonomy_sheet = pd.read_excel(file_path, sheet_name=\"Taxonomy\")\n","\n","# Convert Taxonomy sheet to a dictionary\n","taxonomy = {\n","    \"Root Cause\": list(taxonomy_sheet[\"Root Cause\"].dropna()),\n","    \"Symptom Condition\": list(taxonomy_sheet[\"Symptom Condition \"].dropna()),\n","    \"Symptom Component\": list(taxonomy_sheet[\"Symptom Component\"].dropna()),\n","    \"Fix Condition\": list(taxonomy_sheet[\"Fix Condition\"].dropna()),\n","    \"Fix Component\": list(taxonomy_sheet[\"Fix Component\"].dropna())\n","}\n","\n","# Function to preprocess text\n","def preprocess_text(text):\n","    if pd.isna(text) or str(text).strip() == \"\":\n","        return \"\"\n","    # Convert to lowercase and remove punctuation\n","    text = str(text).lower().replace(\",\", \"\").replace(\".\", \"\").replace(\":\", \"\")\n","    return text\n","\n","# Function to extract matches using fuzzy matching\n","def extract_matches(text, category, limit=3):\n","    if pd.isna(text) or str(text).strip() == \"\":\n","        return []\n","    matches = process.extract(preprocess_text(text), [preprocess_text(term) for term in taxonomy[category]], limit=20)\n","    filtered = []\n","    seen = set()\n","    for match, score in matches:\n","        original_match = taxonomy[category][[preprocess_text(term) for term in taxonomy[category]].index(match)]\n","        if score >= 60 and original_match not in seen:  # Lower threshold to capture more matches\n","            filtered.append(original_match)\n","            seen.add(original_match)\n","        if len(filtered) == limit:\n","            break\n","    return filtered\n","\n","# Ensure all required columns exist in the DataFrame\n","required_columns = [\n","    \"Primary Key\", \"Order Date\", \"Product Category\", \"Complaint\", \"Cause\", \"Correction\",\n","    \"Root Cause\", \"Symptom Condition 1\", \"Symptom Component 1\", \"Symptom Condition 2\",\n","    \"Symptom Component 2\", \"Symptom Condition 3\", \"Symptom Component 3\", \"Fix Condition 1\",\n","    \"Fix Component 1\", \"Fix Condition 2\", \"Fix Component 2\", \"Fix Condition 3\", \"Fix Component 3\"\n","]\n","for col in required_columns:\n","    if col not in task_sheet.columns:\n","        task_sheet[col] = \"\"\n","\n","# Extract Root Cause\n","task_sheet[\"Root Cause\"] = task_sheet[\"Cause\"].apply(\n","    lambda x: extract_matches(str(x), \"Root Cause\", 1)[0] if extract_matches(str(x), \"Root Cause\", 1) else \"\"\n",")\n","\n","# Extract Symptoms (Condition and Component)\n","symptom_conditions = task_sheet[\"Complaint\"].apply(lambda x: extract_matches(str(x), \"Symptom Condition\"))\n","symptom_components = task_sheet[\"Complaint\"].apply(lambda x: extract_matches(str(x), \"Symptom Component\"))\n","\n","# Populate Symptom Columns\n","for i in range(1, 4):  # Loop through 1 to 3\n","    task_sheet[f\"Symptom Condition {i}\"] = symptom_conditions.apply(\n","        lambda x, idx=i-1: x[idx] if len(x) > idx else \"\"\n","    )\n","    task_sheet[f\"Symptom Component {i}\"] = symptom_components.apply(\n","        lambda x, idx=i-1: x[idx] if len(x) > idx else \"\"\n","    )\n","\n","# Extract Fixes (Condition and Component)\n","fix_conditions = task_sheet[\"Correction\"].apply(lambda x: extract_matches(str(x), \"Fix Condition\"))\n","fix_components = task_sheet[\"Correction\"].apply(lambda x: extract_matches(str(x), \"Fix Component\"))\n","\n","# Populate Fix Columns\n","for i in range(1, 4):  # Loop through 1 to 3\n","    task_sheet[f\"Fix Condition {i}\"] = fix_conditions.apply(\n","        lambda x, idx=i-1: x[idx] if len(x) > idx else \"\"\n","    )\n","    task_sheet[f\"Fix Component {i}\"] = fix_components.apply(\n","        lambda x, idx=i-1: x[idx] if len(x) > idx else \"\"\n","    )\n","\n","# Save the updated DataFrame to a new Excel file\n","output_file_path = \"Final_Task1.xlsx\"\n","task_sheet.to_excel(output_file_path, index=False)\n","print(f\"Processing complete. Output saved to '{output_file_path}'.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdM5Y-wsOtm5","outputId":"bbbbe97e-ed00-45ed-8451-6a31d3771386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"]},{"output_type":"stream","name":"stdout","text":["Processing complete. Output saved to 'Final_Task1.xlsx'.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RM7x8AEKPIsM"},"execution_count":null,"outputs":[]}]}